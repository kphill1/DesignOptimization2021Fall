{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "touched-logic",
   "metadata": {},
   "source": [
    "# Theory/Computation Problems\n",
    "\n",
    "### Problem 1 (20 points) \n",
    "Show that the stationary point (zero gradient) of the function\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    f=2x_{1}^{2} - 4x_1 x_2+ 1.5x^{2}_{2}+ x_2\n",
    "\\end{aligned}\n",
    "$$\n",
    "is a saddle (with indefinite Hessian). Find the directions of downslopes away from the saddle. Hint: Use Taylor's expansion at the saddle point. Find directions that reduce $f$.\n",
    "\n",
    "### Problem 2 (50 points) \n",
    "\n",
    "* (10 points) Find the point in the plane $x_1+2x_2+3x_3=1$ in $\\mathbb{R}^3$ that is nearest to the point $(-1,0,1)^T$. Is this a convex problem? Hint: Convert the problem into an unconstrained problem using $x_1+2x_2+3x_3=1$.\n",
    "\n",
    "* (40 points) Implement the gradient descent and Newton's algorithm for solving the problem. Attach your codes along with a short summary including (1) the initial points tested, (2) corresponding solutions, (3) a log-linear convergence plot.\n",
    "\n",
    "### Problem 3 (10 points) \n",
    "Let $f(x)$ and $g(x)$ be two convex functions defined on the convex set $\\mathcal{X}$. \n",
    "* (5 points) Prove that $af(x)+bg(x)$ is convex for $a>0$ and $b>0$. \n",
    "* (5 points) In what conditions will $f(g(x))$ be convex?\n",
    "\n",
    "### Problem 4 (bonus 10 points)\n",
    "Show that $f({\\bf x}_1) \\geq f(\\textbf{x}_0) + \n",
    "    \\textbf{g}_{\\textbf{x}_0}^T(\\textbf{x}_1-\\textbf{x}_0)$ for a convex function $f(\\textbf{x}): \\mathcal{X} \\rightarrow \\mathbb{R}$ and for $\\textbf{x}_0$, $\\textbf{x}_1 \\in \\mathcal{X}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-carbon",
   "metadata": {},
   "source": [
    "# Design Problems\n",
    "\n",
    "### Problem 5 (20 points) \n",
    "Consider an illumination problem: There are $n$ lamps and $m$ mirrors fixed to the ground. The target reflection intensity level is $I_t$. The actual reflection intensity level on the $k$th mirror can be computed as $\\textbf{a}_k^T \\textbf{p}$, where $\\textbf{a}_k$ is given by the distances between all lamps to the mirror, and $\\textbf{p}:=[p_1,...,p_n]^T$ are the power output of the lamps. The objective is to keep the actual intensity levels as close to the target as possible by tuning the power output $\\textbf{p}$.\n",
    "\n",
    "* (5 points) Formulate this problem as an optimization problem. \n",
    "* (5 points) Is your problem convex?\n",
    "* (5 points) If we require the overall power output of any of the $n$ lamps to be less than $p^*$, will the problem have a unique solution?\n",
    "* (5 points) If we require no more than half of the lamps to be switched on, will the problem have a unique solution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-twins",
   "metadata": {},
   "source": [
    "# Note\n",
    "\n",
    "For this homework, you may want to attach sketches as means to explain your ideas. Here is how you can attach images.\n",
    "\n",
    "![everly1](img/everly7.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70e30bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0.25,\n",
       " 0.3359375,\n",
       " 0.22314453125,\n",
       " 0.08416748046875,\n",
       " 0.02147674560546875,\n",
       " -0.0036727190017700195,\n",
       " -0.031863708049058914,\n",
       " -0.07513752533122897,\n",
       " -0.09400811203522608,\n",
       " -0.1015446165429239,\n",
       " -0.1099491842453233,\n",
       " -0.12277055969379447,\n",
       " -0.1283665037090711,\n",
       " -0.13060166485391983,\n",
       " -0.13309461272583495,\n",
       " -0.13689829193229802,\n",
       " -0.13855838549771365,\n",
       " -0.13922146666314117,\n",
       " -0.13996101997278365,\n",
       " -0.14108940748913268,\n",
       " -0.1415818859305425,\n",
       " -0.14177859364189194,\n",
       " -0.14199798737597458,\n",
       " -0.1423327315738453,\n",
       " -0.14247882881061713,\n",
       " -0.14253718355389172,\n",
       " -0.14260226826718575]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The objective function\n",
    "obj = lambda x_2, x_3: (1-2*x_2-3*x_3+1)**2 + (x_2)**2 + (x_3-1)**2\n",
    "# The gradient with respect to x_2\n",
    "grad2 = lambda x_2, x_3: -8 + 10*x_2 + 12*x_3\n",
    "# this is the gradient with respect to x_3\n",
    "grad3 = lambda x_2, x_3: -14 + 12*x_2 + 20*x_3\n",
    "# termination criterion\n",
    "eps = 1e-3\n",
    "# initial guess for x_2\n",
    "x0_2 = 0\n",
    "# initial guess for x_3\n",
    "x0_3 = 0\n",
    "# initial guess for x_1\n",
    "x0_1 = 0\n",
    "# counter for x_1\n",
    "k1 = 0\n",
    "# counter for x_2\n",
    "k2 = 0\n",
    "# counter for x_3\n",
    "k3 = 0\n",
    "# array to store search steps for x_2\n",
    "soln_2 = [x0_2]\n",
    "# array to store search steps for x_3\n",
    "soln_3 = [x0_3]\n",
    "# array to stor search steps for x_1\n",
    "soln_1 = [x0_1]\n",
    "# start with the initial guess for x_2\n",
    "x_2 = soln_2[k2]\n",
    "# start with the initial guess for x_3\n",
    "x_3 = soln_3[k3]\n",
    "# start with the initial guess for x_1\n",
    "x_1 = soln_1[k1]\n",
    "# computing error\n",
    "#error = abs(grad(x))\n",
    "norm2 = lambda x_2,x_3: -1/grad2(x_2,x_3)\n",
    "norm3 = lambda x_2,x_3: -1/grad3(x_2,x_3)\n",
    "from math import sqrt\n",
    "error = sqrt(grad2(x_2,x_3)**2+grad3(x_2,x_3)**2)\n",
    "#error = []\n",
    "\n",
    "\n",
    "\n",
    "def line_search(x_2,x_3):\n",
    "    a = 1\n",
    "    phi2 = lambda a, x_2, x_3: obj(x_2,x_3) - a*0.8*grad2(x_2,x_3)**2\n",
    "    phi3 = lambda a, x_2, x_3: obj(x_2,x_3) - a*0.8*grad3(x_2,x_3)**2\n",
    "    #phi = lambda a, x: obj(x) - a*0.8*grad(x)**2\n",
    "    while phi2(a,x_2,x_3)<obj(x_2-a*grad2(x_2,x_3),x_3-a*grad3(x_2,x_3)) and phi3(a,x_2,x_3)<obj(x_2-a*grad2(x_2,x_3),x_3-a*grad3(x_2,x_3)) :\n",
    "        a = 0.5*a\n",
    "    return a\n",
    "\n",
    "while error >= eps:\n",
    "        a = line_search(x_2,x_3)\n",
    "        x_2 = x_2 - a*grad2(x_2,x_3)\n",
    "        x_3 = x_3 - a*grad3(x_2,x_3)\n",
    "        x_1 = 1-2*x_2-3*x_3\n",
    "        soln_1.append(x_1)\n",
    "        soln_2.append(x_2)\n",
    "        soln_3.append(x_3)\n",
    "        error = sqrt(grad2(x_2,x_3)**2+grad3(x_2,x_3)**2)\n",
    "        \n",
    "soln_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "600751e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " -0.53125,\n",
       " -1.283203125,\n",
       " -1.1663818359375,\n",
       " -1.459442138671875,\n",
       " -1.1904573440551758,\n",
       " -1.1146003156900406,\n",
       " -1.1024794885888696,\n",
       " -1.1885334562975913,\n",
       " -1.1072960920791957,\n",
       " -1.0843905790810595,\n",
       " -1.080617343019604,\n",
       " -1.1061528319691103,\n",
       " -1.0820645410133252,\n",
       " -1.0752726239146204,\n",
       " -1.0741546647758438,\n",
       " -1.0817298944894742,\n",
       " -1.0745838420722769,\n",
       " -1.0725689465701407,\n",
       " -1.07223728501909,\n",
       " -1.074484531275845,\n",
       " -1.0723646046560669,\n",
       " -1.0717668717572766,\n",
       " -1.0716684820837286,\n",
       " -1.0723351436810973,\n",
       " -1.0717062523515053,\n",
       " -1.0715289306301221,\n",
       " -1.0714997426323203]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soln_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "604f4899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0.34375,\n",
       " 0.537109375,\n",
       " 0.5733642578125,\n",
       " 0.763702392578125,\n",
       " 0.7158346176147461,\n",
       " 0.7073152512311935,\n",
       " 0.7220689682289958,\n",
       " 0.7796028356533498,\n",
       " 0.7651041053832159,\n",
       " 0.7624932707223024,\n",
       " 0.7668385705034169,\n",
       " 0.7838979837855664,\n",
       " 0.7795991828104891,\n",
       " 0.7788253178741533,\n",
       " 0.7801146300758379,\n",
       " 0.7851754927846901,\n",
       " 0.7839002043559014,\n",
       " 0.7836706266321409,\n",
       " 0.7840531083215525,\n",
       " 0.7855544487513701,\n",
       " 0.7851761255057172,\n",
       " 0.7851080196803535,\n",
       " 0.7852214856118925,\n",
       " 0.7856668689429293,\n",
       " 0.7855546366575799,\n",
       " 0.7855344325793019,\n",
       " 0.7855680930555639]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soln_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbe4f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "plt.plot(pts, x_1_p, label = 'x_1')\n",
    "plt.plot(pts, x_2_p, label = 'x_2')\n",
    "plt.plot(pts, x_3_p, label = 'x_3')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('log(x*)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7574ce8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The objective function\n",
    "obj = lambda x_2, x_3: (1-2*x_2-3*x_3+1)**2 + (x_2)**2 + (x_3-1)**2\n",
    "# The gradient with respect to x_2\n",
    "grad2 = lambda x_2, x_3: -8 + 10*x_2 + 12*x_3\n",
    "# this is the gradient with respect to x_3\n",
    "grad3 = lambda x_2, x_3: -14 + 12*x_2 + 20*x_3\n",
    "# termination criterion\n",
    "eps = 1e-3\n",
    "# initial guess for x_2\n",
    "x0_2 = 0\n",
    "# initial guess for x_3\n",
    "x0_3 = 0\n",
    "# initial guess for x_1\n",
    "x0_1 = 0\n",
    "# counter for x_1\n",
    "k1 = 0\n",
    "# counter for x_2\n",
    "k2 = 0\n",
    "# counter for x_3\n",
    "k3 = 0\n",
    "# array to store search steps for x_2\n",
    "soln_2 = [x0_2]\n",
    "# array to store search steps for x_3\n",
    "soln_3 = [x0_3]\n",
    "# array to stor search steps for x_1\n",
    "soln_1 = [x0_1]\n",
    "# start with the initial guess for x_2\n",
    "x_2 = soln_2[k2]\n",
    "# start with the initial guess for x_3\n",
    "x_3 = soln_3[k3]\n",
    "# start with the initial guess for x_1\n",
    "x_1 = soln_1[k1]\n",
    "# lamb = ((5/14)*grad2(x_2,x_3)**2 - (6/14)*grad2(x_2,x_3)*grad3(x_2,x_3) + (5/28)*(grad3(x_2,x_3)**2))\n",
    "lamb = (5/14)*grad2(x_2,x_3)**2 - (6/14)*grad2(x_2,x_3)*grad3(x_2,x_3) + (5/28)*(grad3(x_2,x_3)**2)\n",
    "lamb = lamb/2\n",
    "dx2 = lambda x_2,x_3: -((5/14)*grad2(x_2,x_3) + (-3/14)*grad3(x_2,x_3))\n",
    "dx3 = lambda x_2,x_3: -((-3/14)*grad2(x_2,x_3) + (5/28)*grad3(x_2,x_3))\n",
    "while lamb >= eps:\n",
    "        x_2 = x_2 + dx2(x_2,x_3)\n",
    "        x_3 = x_3 + dx3(x_2,x_3)\n",
    "        x_1 = 1-2*x_2-3*x_3\n",
    "        soln_2.append(x_2)\n",
    "        soln_3.append(x_3)\n",
    "        soln_1.append(x_1)\n",
    "        lamb = ((5/14)*grad2(x_2,x_3)**2 - (6/14)*grad2(x_2,x_3)*grad3(x_2,x_3) + (5/28)*(grad3(x_2,x_3)**2))\n",
    "        lamb = lamb/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3fca40b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, -0.1428571428571428]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soln_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b3512cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0.7857142857142865]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soln_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec8dd90b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, -1.0714285714285738]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soln_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a10738",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "plt.plot(pts, x_1_p, label = 'x_1')\n",
    "plt.plot(pts, x_2_p, label = 'x_2')\n",
    "plt.plot(pts, x_3_p, label = 'x_3')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('log(x*)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c607ca7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the Gradient Descent method, the initial values chosen were x1 = 0, x2 = 0, and x3 = 0. The corresponding solutions for this were that x1 = -0.1426023, x2 = -1.0714997, x3 = 0.7855681.\n"
     ]
    }
   ],
   "source": [
    "print(\"For the Gradient Descent method, the initial values chosen were x1 = 0, x2 = 0, and x3 = 0. The corresponding solutions for this were that x1 = -1.0714997, x2 = -0.1426023, x3 = 0.7855681.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c9acfd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the Newton's method, the initial values chosen were x1 = 0, x2 = 0, and x3 = 0. The corresponding solutions for this were that x1 = -1.0714286, x2 = -0.1428571, x3 = 0.7857143.\n"
     ]
    }
   ],
   "source": [
    "print(\"For the Newton's method, the initial values chosen were x1 = 0, x2 = 0, and x3 = 0. The corresponding solutions for this were that x1 = -1.0714286, x2 = -0.1428571, x3 = 0.7857143.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e7673f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "onea = Image.open('hw_2_p1_1.png');\n",
    "onea.show();\n",
    "#[homework](img/hw2_p1_1.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
